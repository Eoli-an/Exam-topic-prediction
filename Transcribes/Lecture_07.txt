Okay, so I started recording now, anyone that will watch the recording later will miss the first two minutes. So just to summarize quickly, today's lecture will be about binary classification and extensions there off in binary classification as the as the problem of asking answering yes, no questions with a computer. I showed some examples here. And what's really important is that we often interested in probabilistic predictions in the sense that we also want to show or estimate our sense of how much certainty we have in any, in any in any of these statements. Okay. So for example, going back to the sprain scan, then we will very likely not be able to make a deterministic yes, no answer. But we want to convey some degree of confidence saying we're 80% Sure. Are we 20%? Sure, or 50%? Sure. Yeah, these are the kind of uncertainties we would like to convey. And particularly if you try to make a prediction about whether a team I mean, whether a team will win this match or not, you're not going to be able to give a deterministic answer, you will want to assign a probability to it. So often when we thought of classification really mean conveying computing probabilities. Okay, we will focus on linear decision rules, like we focus on linear regression last week. Um, so that means that we try to separate these two classes with a line or in multiple dimensions with a with a plane or hyperplane. But without going into details, last time, I try to argue that linear regression, you can very easily use the nonlinear problem by using basis functions, okay. And the same would apply here, if we change our data, transform it nonlinearly then we can make a linear position in this transformed space, and that would correspond to a nonlinear decision in the input space. Okay, I was just mentioning this now what everything I talked said about linear regression also applies here, but we will not be talking about basis functions, specifically, specifically for the rest of today. Okay. So just to introduce some notation, we will have some decision function where we say some decisions on Zed of x, and we can write this as a linear as a linear term, I will sometimes pull out this offset and call it omega zero. But as I explained last time, we can also ignore this and just append a row of our column of ones to x. And then the first entry of omega here will be this offset, so will sometimes show it and then it will not show it but in the end, it's it's really just a question of notation, but we can we don't have to show it we can we could delete it, but sometimes convenient to show this. So, when we have the classification, we will say when this decision function is greater than zero, then we say x belongs to class one or the yes class, when it's less than zero, we say it belongs to class minus one or the no class Okay, and the decision surface, so, the line of points for which we are unsure of where we are, which are exactly on the line will be those points, which satisfy the equation set of x equals zero. And if if we are in a D dimensional space, then there will be a hyperplane with CO dimension one, so with dimensionality D minus one, okay. So, in two dimensions will be aligned, and three dimensions will be a plane and so on. Just to remind you of your linear algebra, the vector omega will be a normal vector to the plane, so the vector omega will be orthogonal to that plane, and will point into the positive class. And, and this offset will determine the position of that decision for surface so we can move around that decision surface with omega and this and the the, the absolute value of that will tell you how far we are from the distance. So, if you go back to this example here, so, then this will here, that will be our decision surface, the vector omega will point here into the positive class. And if we move on, if we move, if you change the offset or make a zero, we'll just move that line to the left or to the right will not change the orientation of the line, we'll just change the offset. Okay. And that's basic, basic linear algebra. Okay, so we spoke about linear regression last time, right? And that was really to fit that kind of function to the data. And so why, and this is a question to all of you. Why can't we if we want to have a silver classification problem? Why can't we use what we learned about linear regression last time, we can just say the label t is now plus one if we're in the positive class or minus one, the negative class, why don't we just use linear regression and pretend visit regression problem? So we use the algorithm we had last time to, to solve to minimize the sum squared errors. And we're now T is always plus one or minus one. But why can we just do that? Why do we need extra classification algorithms? Yeah, so the answer given is that this would be sensitive to outliers. And this is this is this, this is basically one good reasons. Um, so quickly the solution we would get this is just reminding you of last week would be, would be this, that would be the way we calculate omega. And the answer to why this is a bad idea, or the first answer to that is exactly what what you mentioned. So if we have two classes that are sort of nicely separated like this, and they have this Gaussian shape, then if we did linear regression, it would actually give us a very nice decision line, okay. But if we have some outliers, like we have some points here, then they would get a very, very bad, they would really screw this decision line. So why is this? Well, if we make labels plus or minus one, then we'll try to find a line such that on average, it all these points of distance one to it. Okay, so we'll try, which makes sense for regression. Because if the label is plus one, you want it to be one way, or the same unit away from that position line. But in reality, we don't really care whether these points are one way or 50 away from it. Right, we will always get the right answer. So it would be strange to have a regression line and would be biased very strongly to point to the very far away from this session. Okay. So this is, this is definitely a a good reason. I think there's a bit of more of a kind of statistical or probabilistic reason also, because it in some ways, you could say it's just the wrong model. Okay. So the way we introduced linear regression last time is by saying, well, we assume that we have some noise, and that's Gaussian. So we have this prediction. So this is the model we had last time, our model for T is that given x t is given by a Gaussian distribution with the mean y of x and some variance sigma squared. But obviously, if plus a one plus one or minus one, a two numbers that are not from a Gaussian distribution, so in some ways, we would be approximating a binary distribution with a Gaussian distribution, which, from a statistical perspective is a very bad approximation. And that will have consequences. Okay. So last time, we was talking for Gaussian for linear regression, we could motivate not only by least squares, but also by maximizing this conditional log likelihood, where we pulled in a Gaussian log likelihood of observation model here, okay. And for binary classification problems, we really need a likelihood here that's suitable for binary variables, and not an our calcium levels. But before we get to that, I just want to point out a important but somewhat subtle point. Note that in linear regression, and the same will be true in logistic regression, we maximize the log likelihood of the T's given the x's. So we write our distribution over the T's, and we conditioned on the Xs. So we never have to write down a distribution over the probability of my data x, we just have to write down the distribution over the labels, okay. And that's important, because the labels here are binary. They're very simple to model. But the x's might be 100,000 dimensional vectors, which is very hard to write down a probability distribution for them. So it's convenient for this regression model. So we just have to condition on the axis, we don't have to model the axis themselves. Alright, but now let's look for a distribution. So in this case, we want a conditional distribution for binary outcomes. And I'm sure, um, you've seen this likely both in this course, but also before, there's a very easy distribution for binary outcomes, I think, somewhat confusing. It's called the Bernoulli distribution, not the binary distribution, but it's the only distribution that makes sense. So given some probability p, the probability of the observed observation is one we call this P and, and the probability that the observation is minus one is just one minus p, there's only two possible outcomes. So one is probably P and the other one has probably one minus p. And now we just have to make this probability P dependent on our data. So now, we want to make this probability P dependent on the outcome of our regression function. And this regression function can be any number It can go from minus infinity to plus infinity, right? So and probabilities have to be between zero and one. So when someone to squash, the output of that function to make sure that it goes between zero and one. And there's a standard function for this, and we will be using that is called the logistic sigmoid function. So that is a function that has this shape. So as a function of that, it will take the input set and will return an output that's between zero and one. So we can just call that the probability, okay. And if the output is very positive, so let's say plus eight, so if the input is very positive, then the output will be one, if the input is very negative, the output will be zero. If the input is zero, the output will be point five. And that makes sense, right? I said when that of x equals zero, we're on the decision surface. And we don't know. In that case, the probability we signed for going for one or the other class would be point size. Okay. So when the input is zero, the probability is point five. So we don't know whether we should go left or right. And you could obviously, there's many functions you could use to this, you could use any function that takes inputs between minus infinity and plus infinity and returns outputs between zero and one. And there's other functions that people use as a private function, for example, we will just be using the logistic sigmoid here. And in your exercises today. Or next week, I guess. There's also some reason as an exercise, which says, Why for classification problems is in some ways, the natural choice to have yoozoom that your classes are Gaussian, and you derive the function from that, then you would be getting exactly the sigmoid non linearity. Alright, and that everything together. So last time, we had linear regression, or Gaussian linear regression, where we had a linear model and a Gaussian likelihood on top, now we have a linear model, put the output through a sigmoid and then have a Bernoulli distribution on top. And that algorithm is logistic regression. So we've completely defined what logistic regression is. Are there any questions about this at this point? Okay, so what we are writing down is a model. So that sorry, the question was why how we use the vanilla distribution. So, we given, we want to write down a probability, let's maybe go back to the example, we want to write down the probability that the home team will win the match, okay. And we have some features that we collect, and then, and then we can compute a linear function on those features. And then from that, we want to derive a probability, and we want that probability be between zero and one. And so we take the output of our regression of our regression function, put it through the non linearity, and then we get a probability of point nine. And that means we predict with 90% probability that the home team will win. And so the observations will then be given, if we do this many times the observations then well will then be given by a coin flip. So we say when we flip a coin, then with 90% probability will come up as team one wins. And with 10% probability will will, it will come up with the other team wins. So it just it gives us a model for how much answer how much scatter we expect in these outcomes. Obviously, if we're very sure, then this might be almost deterministic. So the output might be point 9999, we're sure that of a given outcome, and then there will be hardly any stochasticity left. Okay, so the model I just defined is called logistic regression. And when you go back to the example before, in fact, when you do logistic regression, you will get the green line in both cases. Okay, so logistic regression will not be sensitive to these outliers here. But we'll just keep these separate these two classes. How would we do this in practice? Well, we wrote down on a model that has a free parameter omega. So practically, we would have to estimate the free parameter. And we can do that, for example, by by using maximum likelihood estimation. And one feature that we saw about Gaussian linear regression last week is that this is close from solution that we can write down. In this case, for logistic regression, this is not the case. So we have to maximize the log likelihood numerically, if you do maximum likelihood estimation. And the log likelihood is given by by given by this form here, okay? And this is a little bit this is more complicated than it, then it looks like our sorry, this is less complicated than it looks like. Okay, so the formula looks much more confusing than than the underlying the logic is. So let me let me try to let let me try to verbally explain what this really means. So let's say our first output, so we want to write down let's ignore the sum here for the moment. So let's just say we want to write The likelihood of our first observation, and our first observation can be one or minus one. Okay? So let's first deal with the case that the observation is one. If, okay, and there's okay, there's a terrible mistake here, that should be minus one. Okay, that makes it more confusing, I will fix that should be t minus one, over two. Okay. So let's say, um, let's say t n, the first observation is one, then we have one times not by n, and t n minus one, this term goes out. So this term goes out completely, we just have T n times log wire. And Tn is one. So the log likelihood is just log of y n. But what is yn? Well, y n is just the probability of this coin flip. So the log likelihood is just the log of p, the log of the probability, literally, I mean, you can't have a log likelihood that's more literally just the log of the probability, the coin coin flip probability p is the same as y. And that's the only term that survives here. Everything else is zero. If your observation is minus one. Sorry, I have another typo in here. Dammit, dammit. Okay, let me I have two typos in there, let me fix those, I will update this slide and put a verbal expression on it. I changed notation on this last time, and then a few confused indices, but it should have been writing. And I will do this on the board now. Because that's, that's easy for the people, I will fix this, I would write this on the board number six on the slide. Okay. But what I should have written here, what I wanted to do, and then confuse myself is our labels tn equals one, or T n equals minus one. And we can redefine a new label s n, where we say SN equals one in the first class, and S N equals zero in the second class, we can just redefine that, okay. And then we can write on a log likelihood, where we say the log likelihood is just Tn is just log of y n times n plus one minus s n times log of one minus ln, okay. And, and if the label is one, if tn equals one, then the only term that's a vice is the first term and the second term goes out. And if the TN is minus one, then we redefine this as a new label SN, which we call zero, and then the first term goes out, and the second term survives, okay, so and test that conversion from one to one and minus one to zero is what it did in my head last night, which I messed up. So this is, but the whole logic here is that the likelihood term is just whichever of those two terms survives, okay? And just gives the probability of P on 34 minus p. And just if we write it up in this combined form, then it's, then it's confusing. And if you make errors in your mental arithmetic, then it gets more confusing, alright. But the important thing is that this is some function, or the corrected version of some function, we can optimize numerically. And the good news is, we will not go into details. But the good news is that this is a very friendly optimization problem. So it's very easy to solve this optimization. And why is that because this last function that we get from this is when we try to minimize the negative log likelihood, it's a convex function. And convex functions are easy to minimize, because there's exactly one minimum, and we just follow the gradient, or one way to find is just to follow the gradient till we're at the global minimum. And there's no messy optimization landscape where there might be multiple local minima. Okay, so for logistic regression, we're always in this regime, and we're not in that regime. And because the negative log likelihood, if you want to minimize it, it's a convex function, and the no local minima to get stuck in. And they're very good optimization methods and theoretical results for convex problems. Okay, so convex optimization is probably the most well studied form of optimization. So there's tons of theory and methods to deduce which is not which is beyond this course, but it's no optimization problem to be afraid of. And the easiest way to optimize it is using gradient descent. So you start at the top and you just follow the gradient to be at the bottom and you try to and because there's no local minima, there's no rocks or something you can So run into you can always go straight down till till you undervalue. There's more efficient methods than logistic regression. But for the purpose of this course, I would not worry about it. But basically, there's tons of toolboxes for this, including sack learn that have very efficient routines for, for solving these kind of problems. You just have to know that you don't have to worry, basically. Okay. Bayesian logistic regression. So everything I spoke about now was in the context of maximum likelihood estimation, okay, so we try to maximize the likelihood or we try to minimize the negative log likelihood. What if we want to do it in a Bayesian manner. So I wrote down maximum likelihood estimation, before that, we try to maximize the log probability of the Omega given the D, given the data. And if you want to have a prior over parameters, then we get the easiest thing to do is to maximum a posteriori estimate or the map, in which case we maximize as something that's, that's the posterior or proportional to the posterior. So the log in this case will be log likelihood plus a log prior, where this p of omega corresponds to some prior distribution. Okay, it's the same game that we had for linear regression. For linear regression, we had a closed solution, this case, we don't have a closed solution. But if we choose a reasonable prior for which the log probability is convex, so that a Gaussian, then this is still a convex optimization problem. So for reasonable choice of the prior, this is a very easy optimization problem. Okay. And how this is all you're gonna have to worry about in this course. And there's plenty of toolboxes. I should also point out there's a little subtlety, if you use, I can learn and you do logistic regression. It actually doesn't do logistic regression, but it does Bayesian logistic regression, it doesn't tell you that, okay, at least it didn't in the past, maybe they've changed it into now. So what it does, if you, you, if you do logistic regression inside could learn, it assumes that you want to use a Gaussian prior with a variance of one. Okay? And that might be fine. But it might also be terrible, depending on how your data is scaled. Okay, so it's just, I, it's one of those things where one has to be a little bit careful. If you use a toolbox, it might make assumptions about your progress, or might assume a priori that you're not fully aware. So it's always important to read to read the label. Okay. So there's nothing wrong with using scikit learn, but it's important to know what it does. And this is one of those cases where it might not do exactly what you need us to the question of the back. versus not using any prior? Well, let's that really goes into this question of when one wants to maximum likelihood estimation when you want to be basing. Okay, so I don't want to give the big answer like between these two different ways of thinking about it. The practical answer is, if you have a vs. If you have a Gaussian prior, it will make sure that you don't have single weights that are too extreme. Okay. And this actually, in one scenario in which this can happen, is if you have two classes of data points that are perfectly separable. So there's a, the algorithm can give you a perfect answer. And then nothing. And you can always keep optimizing the log likelihood by making the method more and more and more confident. If there, if you have 50 data points, and you can perfectly say these 25 on one class and the other 25 on the other one, then nothing stops it from getting extremely confident and say, I'm 100% Certain, and one probably never wants seven algorithm that's 100%. And if you use a prior, then it will keep the omegas in check. So we'll make sure that the algorithm doesn't does not get too confident. So I would basically never use logistic regression without a prior, you just have to make sure that the scale of the prior is not completely mismatched to your problem. But I could learn does, which is a reasonable Ristic. But even that can go wrong. They just assume your inputs are scaled have variants one, and then they think is reasonable that the output also has variants. One, it's not an unreasonable assumption, but it's one that could be pretty wrong given given, given the nature of depending on the problem that you're trying to solve. Okay. Estimation points, the expression of the given omega, the first term of course, yeah, I there's a typo on the slide, which I'm noted down at six. So the Pusteria is log of p given the posterior is P of omega given D, which we can write as the likelihood p of t given omega plus log. So that's F Well spotted, there's a typo on the slide, whichever, whichever fix, okay. So the version of the slides that I uploaded today will obviously contain these errors. But I'll uploaded one later today, which I, which they fixed. If you haven't downloaded yet, then maybe wait, wait for a few hours. Alright. And, obviously map is not full Bayesian inference. I will not really talk about full Bayesian inference today, I will just want to very quickly sketch how we would do it. But I will not go into details. And this will certainly not come up in the exam question that lies, at least at least for this lecture. Again, as reminder, why can full Bayesian inference be useful? If you get the full distribution over the omegas, then we can compute things like error bars, and predictive uncertainty, and things like model selection active learning more efficiently than we would do if you don't have this full posterior. Again, the bad news for logistic regression is there's no closed form solution for the posterior. And so we have to approximate it. But the good news is, this is still a relatively well behaved. posterior distribution in the sense that it's not Gaussian. But in some ways, it can be very close to a Gaussian. And in particular, it's always uni modal. So you can't have this case, we have a distribution that has multiple bumps, it always is like a Gaussian ish shape. But it's not not perfectly Gaussian. But approximating by Gaussian is typically a very, very good approximation. So there's different ways to find such approximation. For example, the Laplace approximation that you've heard about before, which is quite simple and works exceptionally well, in this case, because the procedure distribution is pretty Gaussian. But there's also more sophisticated methods such as very, such as variational inference, or doing MC MC sampling. But this is a kind of this is as nice as posterior distributions get. It's not quite a Gaussian, but it's almost, it's typically almost a Gaussian. Okay, more importantly, for this course, we will talk, I will talk a little bit more about how to interpret the weights of a logistic regression. And I will step back one step more, and go back to this linear regression case, and try to discuss a little bit how we can how the terms in such a model should be interpreted. And just, I mean, to remind you, in the linear model, we have this observation that the mean of our observables, we think this is a linear function of the inputs. In this case, we have one offset and a few different data points. And if so, the prediction that this model makes is if we move one of those x i by delta I, so if we add delta i to one of those x i, but we keep all the other data point six than the output of the model, the prediction will change by omega i times delta. Okay. So if I add, let's say, an offset of five to the first 2x, one, then the prediction will be that the output changes by five times omega one. Okay. So that's, it's a linear model. So the it's sort of very easy to, to reason about these things. The important things to keep in mind here is that the assumption is that all other x is fixed. So this prediction only makes sense if we have the ability to change one of those x's without having to update also the others as well. So what how would this be interpretable? If weight is zero, if omega is zero, then obviously the prediction is that if we change x, that particular x, then it doesn't doesn't change the the output. So if omega one is zero, it means that x one doesn't matter. Because if you change x, and the output doesn't, doesn't change at all, okay? So that's easy, easy part of the prediction. In contrast, if we have an omega one, which is very big, in absolute value, that means the model output will be very sensitive to changes in that in that variable, okay, so when a change, when a change x one, and omega one is very big, then that will change the output of the model a lot. And the interpretation is that this x one would then be very important, very sensitive, and we'll be the model will be very sensitive to x one, so x one seems to be important for that prediction. To make this a little bit more concrete, if you use an artificial example, that's loosely inspired by by one and the Gelman HiLine Viteri book. So let's say we have a regression model, where we tried to predict the weight of a person measured in pounds using these covariance, so we have some constant offset omega zero. And we've collected some statistics, we've collected information about the height of a person in inches. We've collected information about the we know the age of the person, and I will assume that this is an adult person. So where when everything we're the height doesn't change with the for the age anymore. Okay, so everyone, only grownups We have a third predictor. That is, and we say this third predictor is one if the person is male, and we say that predictors zero if the person is not male. And then we have a fourth predictor, which we say is binary. And we just say, Does this person have an advanced education? Or does it not? Okay? So this is the regression model, we can set up, we can collect data, and then we can fit. We can fit all these terms. And what I want to do with you now, before I sort of show you something like an answer is, if you fit it such a regression model, what would you expect these coefficients to be? And how would you interpret them? So maybe, let's start with probably an easy one, we like to expect that the weight correlates with the height, right? A taller person, we will say on average, is heavier than a person is less tall. So we would expect omega one to be a positive number. Okay? Maybe let's ignore the other points, what would you expect omega zero to be? The average rate. Any other other expectations. Alright. Let's ignore omega two omega three omega for now. But let's say this is the average weight. I don't know what the average weight is. But let's, let's say it's, I don't know. Let's say it's something like 150 pounds, I'm just making this up. So that would be 150 pounds. And then let's say the height would be something like, let's say, let's do in centimeters, let's do something like I don't know, 160 170. And then you would have have 150 plus something that's proportionate to that. And so what you would see here is, if I define this as to be the height in inches, not relative to the mean. So your answer would have been correct. If I would have rescored, all of these to be centered around zero. If all of these have zero mean, then omega zero would be the average weight. But if I define them all in absolute terms here, so that height starts at zero and goes up and 12345 inches, then this number here has to compensate for the fact that these are not zero centered. So if, if my other covariance is zero centered, then that would be the mean. But if they're not zero centered, there would be some term that corrects for that, in fact, if you did this regression model, this would be very, very strongly negative number. Because all these things are positive. So they always push things to add to a positive number. So to compensate for that omega will be will be a negative number. Exactly. So if, if I balanced my design matrix, which would mean that all of these things have zero mean, then for an average person, all of these things here would be zero. And then for an average person, this would be them. So if I wanted this to be the average weight, I would have to rescale all the other variables such that they're zero, they have zero mean, because then the average person, all these terms will drop out. And that will be determined, right? How would we expect omega two to be anyone? That would be a positive number. assumably, right? Because when even when people have grown, at least, for many of their adult years, there will be a correlation between weight, weight and an H. So people, on average, get heavier, at least until the point, the third point would be, what would be omega three? And what would be what would be the interpretation of Omega three? Or Omega three? Well, I mean, let's, let's say what what's, what would the interpretation of Omega three omega three would be if all other things are equal? So if we take a male person, and a person is not male, and we they have the same height, then the same age and they have the same educational status? What would we expect the difference in YT? Okay, and so the interpretation of Omega three would be everything else being equal. What's the average difference in weight between a person and a person. Okay, that would be the interpretation of Omega three. And these are often. And this is often how these kinds of models are used. So we want to find the difference between one or multiple groups. And we want to isolate differences, while kind of getting rid of other terms that also influenced the measurable, okay, so if, obviously, height and age have a big influence on weight, so we want to discount that. So we pull that into different regression coefficients, and then we can isolate terms that only correspond to some thing that we might be interested. Okay, and the fourth point, omega for any guesses mahmoodi expect that to be omega four, if you run this regression would also be a positive number. Sorry, it would be a a negative number, on average, across the population or across different population, weight is negatively correlated with education status. So everything else being equal, on average, a person with a higher education status would weigh less than one with a lower education status. Okay. But this, so now, I think now, now, one point that I really want to make, and I think this is one place to do it is the important thing, again, is these are not to be to be interpreted causally. Okay, so this is just a way to capture correlation or statistical patterns in your data. But obviously, let's say on the day that you get your master's degree, let's say then, in this however you do this classification changes you from having advanced education a lot. Obviously, the prediction would not be that on that day, your weight drops. Okay. So it's not meant to be a causal. I mean, there might be a big weight that drops off your shoulders, but your your body weight will not change on the day. Okay. And also, if you want to, if you want, I mean, and I think if you want to, like come up with policy recommendations, so how, for example, could you change the health in a population, then even if you find a positive regression, wait, and one of these things, it doesn't have mean, that gives you a way, like a policy into action? It doesn't mean like, oh, everyone should have a master's degree, and then some problem will go away or not. Okay. So, so the important thing is these, all of these things capture status statistics in the data that you have. And they can provide hypotheses for causal perturbations. But in themselves, they should never be interpreted as we have evidence that this or this happens. And they often are, right, you often read these regression models, and they find, oh, we find this difference here. So we really think this is good, we have to do this, or do the following things. And then your grades will get better, because statistics have shown that people that sleep longer have better grades. Or vice versa, I don't know. But in either case, it's just some correlation. Okay. And if you put that correlation, a big regression model, it's still a correlation. And that's really important to keep in mind. Alright. So I think I've said these points here, I think, basically, everything we discussed now. So omega two will tell us how much weight two people gain per year with age on average. Omega three will tell us everything else being equal. How much heavier is an average male person? Here's an observation that I didn't mention. All of these things depend on the units, right? So if you change the units, from heights, from inches to centimeters, then omega one will obviously change, right. And in fact, when you change it, omega one will suddenly get much smaller. Because centimeters, always much bigger numbers than inches. So if you change the units, then omega one has to compensate for that, by that factor. That doesn't mean that now height became a less important predictor, it just means that we have to always keep in mind what things are scaled relative to the question? So so the question is whether it would be sensible to normalize all these inputs. And the answer is, it really, really depends on what you want to do with it. Right? For example, if you want to interpret your omega two is how much weight two people gain per year with age. That will give you a number in, let's say, kilograms per year. If you normalize your data And we'll be answering we'll be in relative to the standard deviation of ages, and moving by one standard deviation will change your weight by five kilograms. Okay. And that's less useful than to know on average, you're going to gain one kilogram per year. Okay? So depending on what you want to do with your model, using normalized coordinates might be more or less useful than using interpretable units of measurement. And it's the second point here, that weight is inversely correlated with education status. So omega four would be negative, but this is not. Again, this is one of those many cases where there's not important really not think about this as an as a causal. As a proof for causal relationship, it might be called it might not be causal, but the regression model in itself does not convey evidence for that. Okay, any questions about this? Yep, that's, that's an excellent point. And the way I talked about this is, I basically assumed that all so the other subtlety in the interpretation is that we make this assumption that we can be can manipulate these things independently. Okay. But again, they might be, they might be correlated. And I will not use the example that you mentioned, I'll use another one, and then come back to that. But there was a reason why I wrote for an adult person. Because if you were thinking, let's let's, let's ignore maybe the Omega three and Omega four for the moment, and just assume we apply this to kids. And obviously, for kids, the height is very strongly correlated with the age. Okay. So then obviously, it's sort of weird to think of H changing, for example, without the height change. So this causal, if you think of the age changes, but the height doesn't change that kind of in some ways, doesn't. It doesn't make sense, because for most kids, that's not something that would happen in reality. Okay. So once your inputs are inherently correlated, then this way of thinking about this prediction as being perturbations becomes tricky. And the example that you mentioned, is, is related to that. So let's say, if, if there's an there's an average difference between education status between see female or male participants or entries in the data. And I when I, when I made this example, I thought about it that this dependence would be sufficiently small that we could ignore this, but I'm not actually sure this, then obviously, then then the interpretation gets harder. Because if the difference like whether someone has advanced education or not, which statistically also tells you information about whether they're male or not. And then thinking about these perturbations is manipulating one without on average perturbing the other one becomes much harder to interpret. So these regression coefficients become very hard to interpret when your inputs x are correlated. And that really makes makes interpretation much, much, much harder. Any further questions? Exactly. So this, the correlations of the inputs, they don't mathematically change anything about fitting the linear regression model. In fact, that's what if you pick up a machine learning book, they would not ever talk about this, because it's not a problem for prediction, but it is a big problem for interpretation. Okay, so now let's go to logistic regression. And for logistic regression, things get a little bit more complicated. Okay. So for logistic regression, we had the probability of T equals one being the correct label as a function of a conditional our data x, and we wrote this as a sigmoid. With that, with that input, and I terribly have another typo. There should be a there should be a little too I got so this should be a sigmoid of this. And the sigmoid has a minus here. Okay. But let's, I will fix that. So the important thing is that the probability is some nonlinear function of the input. So when we change the input, what does it imply for the probability? Well, we have to move everything through that nonlinear function, right? One thing we can do is, we can write the following thing that's slightly weird we can write the probability that we had before the probability of belonging to the positive class given x divided by the probability of not belonging to it. Okay, so that's the probability of being in the positive class divided by the probability of being in the negative class. And if you have only two classes, then these will be, they will have to add up to one. So that's probably of one event minus a divided by the poverty of one minus that event. And for logistic regression, if you insert this equation, and you put in the minus sign correctly, and you do everything, then you will find that this becomes this term. So this ratio here will be the same as the exponential of our linear terms, or the log of that ratio will be linear in the in the inputs. So everything I said before, about trying to change, if you change one of the x's in the linear regression model, they change your prediction directly, by changing the mean, here, they change this weird thing here. So if you everything we said before, if you think about it, in a regression context, in a logistic regression context, we'll change this bizarre term here on the left side. And we'll try to talk about what this term is, and how one can interpret it. But everything here is modular, this mistake here is just a very small tick, right? You just divide by it and put everything in and you find this template, okay. And then you and you take the log on the left and the right side and get this log ratio is linear in the parameters are linearly outputs. This term here, this ratio is called the odds of the event t equals one. Okay? That's just just the term of it, it's a bit of a weird thing I will talk about a bit more, but it's just the ratio of the the of the probability that it happens divided by the probability that it doesn't happen. It's called the odds of an event. So changes in x linear change the log odds, the log of the odds, okay, that's how to interpret the output, I find odds to be appropriately named because they find an odd and unintuitive. And we'll talk about this a little bit. And this makes interpretation of these models hot. Just some examples of a some event A has a probability of 50%, then the odds of a are 50%, divided by one minus 50%, which is 50% divided by 50%, which is, which is one, okay. So in event that has equal probability of happening or not happening has an odds of one. If you haven't event with it, which has a probability of 10%, or one over 10, then the odds of the event are one of a 10 divided by nine over 10, which is one over nine. And I find it almost impossible to think of one over nine as anything else, then this event has probability one over nine. But that's not the case. So the way we have to interpret it is, so it's always tempting, I find extremely tempting that one of the odds of one of the nine means this happens, one in nine cases. But that's not what it means it means it will happen one time on average, and will not happen nine times. So will happen one in 10 cases, not one in nine cases. Okay. So odds are not probabilities. So we can think of them in that way that there's all cases and you take the ratio of the case of what does happen divided by the cases where it does not happen. If any of you ever lived in the UK, and or did sports betting, which I hope, I mean, I hope at least latter part is not true. And then one thing that book makers are people that offer bets in the UK do is they would not tell you, they will always quote the fractional odds. So they would say, if you want to bet on Everton vs asmall, and you want to put money on whether there will be a draw, then they would offer you odds of 14 to five. Okay. And, and that's I. So if they, what that means is, if you bet five pounds, that there will be a draw, you will get 14 pounds back, and you will also get your five pounds, think back that should be apparent cost. And this is sort of the odds that this is the reward that they offer you. And that will be a fair bet. If the probability of a draw happening is five divided by 14 plus five, which is 26%. So this this, this is reasoning. And I mean, if we think of one like a fair bet being one of the probability then the way to think about it, which I think makes it slightly more intuitive is this thing where you say, if you it does, it's not the probability of this happening versus not happening. So it's not five divided by 14 is not the implied probability, but it's five divided by 14 plus five, because if you win, you're going to get 14 and defies that you put in Okay, So I'm not sure whether it's helpful for you. But if you think of logistic, so logistic regression models become very intractable when you want to use them for betting in the UK, okay, so maybe this is, this is the part but they're not useful, I find us really think they find it very hard to think of odds. I should mention that if any of you ever work with statistical data and medicine, then odds ratios are used a lot in medicine. And it's not the case. And there's reasons for why this, which I will not go into, but it's not that they're just strange. But it is because in many situations, you have data with which you can estimate odds ratios, but you cannot estimate other things that you might be interested in. So often, in medical statistics, they work with odds ratios, because the only thing they can estimate fully knowing that it's slightly hard to interpret. Okay, so odds become much easier to interpret. In cases where we have very unbalanced classes. Okay, so let's say, and one context, where this comes up is risk factors, let's say there's some disease, and that disease has a very low probability. So even with all the data you have, you will always it will always be unlikely that someone develops that disease, okay. And if that is the case, the probability that someone doesn't have the disease will always be almost one. Okay. So if you think of, I don't know, the, the maybe the early times of Corona where like, it was very rare, then on average, like it would be very rare for persons. Okay. So in that case, at least approximately, you could think of this probability being being one. And then there's odds ratio, the probability of someone having the disease divided by the probability of someone not having the disease is approximately just this probability of someone getting the disease, okay. And then we can write down our logistic regression model. So then it just becomes rather than being this odd ratio is just the probability that someone has the disease is an exponential of some inputs. And let's think of those inputs as some base input, omega zero, and plus some other inputs. And I assume that each variable has binary. So you just say you have some covariates, for predicting whether someone has the disease, whether they're a smoker, yes or no. Whether they're obese, yes or no, whether they have high blood pressure, yes or no. Okay, so let's say these are the predictors of your model, and then the interpretation of the output becomes relatively straightforward. So the first invitation would be if you don't have any of the risk factors, so you're not a smoker, you're not obese, you don't have high blood pressure. So it should be w three omega three here, then your risk of having the disease is just exponential of omega zero. So exponential of omega zero will tell you, what's the probability that someone that doesn't have any risk factors will have that disease, okay. And if you're a smoker, then your probability of having the disease will just be exponential of omega zero times exponential of omega one. So your risk of having the disease will go up from exponential omega zero to exponential omega zero by exponential omega one. And the kind of thing that you would sort of write about this is saying, smokers have a three times high ratio and have a three times higher risk of developing a disease than people who don't smoke, okay. And, often, and you would sometimes even find that what the study does is actually fit a logistic regression and count and, and and get the, the lock the odds ratios or the ratios, but then when they communicate it, they would often write this as these risk increases, and it would implicitly assume that you in this regime where everything is quite rare, so this approximation is okay. Okay. And this is one of those cases where you might have even read about the output of logistic regression capital like this saying, there's a five times higher risk for people that have a following condition to develop another disease or not. So in terms of these, you might have heard the word a lot of like a risk factor that plays into this. Again, going back to the point that you mentioned earlier, one subtlety can be that these different risk factors are can be correlated, okay? And then interpretation gets, I mean, they can be correlated, and they can interact in nonlinear ways. So it could be that for example, you have a disease which only ever affects smokers that are not obese. Okay, and then this simple way of summing up these risk factors and multiplying them will not give you the right answer. And similarly, this thinks this is not meant you it's also one has to be careful to not interpret this causally, it doesn't mean that if someone loses weight, then suddenly they will be less likely to get this disease or not. Or if they stop smoking, then will that risk drop down? Okay, so many of these things are really correlations in the data. And you would need additional evidence to make a causal inference from that. And there's a question in the audience, which says, if we find a correlation, does it mean we can be more certain that there's a causal link? And they will, I will, this is not election causality, but mathematically, a correlation does not in any way. provide any hard evidence for for causal link? There are some situations in which does, but in most cases, strictly speaking, a correlation does not imply a causal link. But it's often suggestive of is often a reasonable, I mean, often provides predictions for causal links. Okay, so one thing you would definitely see is, you would definitely see is that it's used in this way, I don't know, there's one plot that you might have seen, even this caused a lot, where for different states, in different federal states within Germany, or different Buddha's lender, you see the plot of vaccination rate versus number of the incidence of Corona. So you would see that states were, which have vaccinated a lot, they have a low incidence in states that had not vaccinated a lot. Okay, that's a pure correlation. That's a pure correlation. So it doesn't mean in itself does not show that vaccinating helps. And keeping out the right, that plot in itself does not show that. But it's, it's strongly suggestive that it does, and it can give you a good reason to search for, for further evidence, for example, or to and it's or it's at least consistent with evidence that obviously this helps, okay. And and there's many examples of this where strictly speaking, in itself, the plot just shows a correlation. But, some additional reasoning can also show that this is likely also showing a costly, but the plot in itself, just plotting one thing against another thing or betting one thing against another thing is in many situations, not not any proof for cosmic. So this would, so the question is whether one can mathematically formulate this, the answer is no. Because, like not, not in, I mean, not in full generality. And but there are so so there are situations where correlation proves a causation with additional assumptions. Okay. And and they are and so one of those examples is where you can if your inputs okay, let's, let's say you can randomly you your data that you've collected comes from the scenario where you were able to randomly change your inputs, then the correlation, and that's what you basically do in a clinical trial, you do a correlation. But you know, the axes, you can randomly change, because you can randomly put people into the treatment group or the control group. And you know that this x is then not correlated with anything else. So if you can randomly change your inputs in a way that's not correlated with the output, then and then you do a regression model, then you can show that this proves a causal link. So for example, if maybe it maybe, maybe let's see what that example works. But let's say you could randomly change, let's say, the different vaccination rates in different states in Germany, you could randomly perturb them. So you could say that some states where we just we be take out our I don't know, our states, and for some, we decide we vaccinate the others, we randomly decide we don't. So then you're you're either lucky to live in a state which vaccinate or not, and then you would later plot the corona rates in the States, which you randomly picked to be vaccination states, and then would be a causal link, okay. So that if you did that, then it would be causally related. In reality, whether state vaccinate or not, or has a high vaccination age or not correlate with many other things that might also influence your Chrono count. And because you can't rule out these indirect influences you can make a call alright. We had two examples now of linear ish regression models, linear regression, where we said the inputs that we have provide a linear prediction of the mean observation. And we had logistic regression where we said the inputs that we have provide a linear prediction for the log odds. So we had these two cases, linear regression, predicting Alcyone outcomes. And the mean prediction was a linear function of x. And we had logistic regression for predicting binary outcomes, where the mean was a sigmoid of a linear function of x. So the mean probability was a sigmoid of a linear function of x. So the mean was a nonlinear function, a sigmoid of a linear function of x, right? First example, mean is a linear function of x. So mean, you can think of the mean is a linear function of linear function of x. Second cases mean is a nonlinear function of linear function of x. Okay, so the pattern, I mean, only n equals two, but the pattern that you could start seeing is we have some model, and the mean of that model is a nonlinear function of a linear function of the inputs. Okay. And to jump ahead, that's going to be called a generalized linear model at some model, and the output is a nonlinear function of a linear function of the input. That's why it's not a linear, not a linear model, but a generalized linear model. And why when might this be useful? Well, for example, we might have a scenario where what we try to predict accounts, okay, so we might want to predict the number of new COVID cases in a district, we might want to predict how many action potentials, let's say a neuron will fire. So between 0123, we might want to have a tool that predicts how many emails will arrive in the next five minutes. So these are all cases where what we're trying to predict, are counts 012345, up to I know, in principle, infinitely many are very large number, but this is a count, okay. We can't do logistic regression for that. Because logistic regression could only do 01, but it couldn't do two or three or four. And we can't really use calcium for that. Because if we just have a small number of counts, then a Gaussian distribution is a terrible approximation for this, right, because the Gaussian distribution is continuous valued and can be negative, and counter discrete, and they cannot be negative. So if we want to predict counts, then we would like to have a distribution. That's not adults in distribution, it's also not a binary distribution. But we would like to use a distribution for counts, for example, the possible distribution. And then plus our distribution is is, is the distribution which has this following probability mass function, the probability of observing T events is Mewtwo, the t exponential of minus nu divided by T factorial. And in fact, here, this parameter, mew is the mean. So if, on average, we expect 100 emails the next five minutes, then you would be here 100. Okay. Or if expect 100, COVID cases, then you would be 100. But obviously, even if on average, we expect 100 cases, we could also it could also be happening that there's no use case detected, right, in which case, the probability of no cases would be would be a very, very small number. But this is a distribution over accounts given to me. And if you want to use the same spirit that we had, before, that we have a model that kind of linear, but has the correct observation model, then we would like to have a linear regression model where the outputs are not Gaussian. They're not binary, but their personal distributed. So given our inputs, we have a Poisson distribution over the observables. And the mean, of that model is given by a linear function of the input. Okay, so could we, so can we, would it be possible for us to just say, well, let's just take the mean, and say the mean is a linear function of the inputs? Would that give a sensible model? Does anyone try to answer that? Could we just do that? Could we just say, well, the mean, we just predict that the mean count is a linear function of the inputs. We'll be strange about doing that. So Yeah, exactly. So they said he has a linear function of the inputs. And depending on my weights and the inputs, that could be negative, right? And then the prediction would be, my prediction is that on average, you're going to get minus three emails in the next five minutes. And that, that doesn't make sense. And in fact, when you try to plug this into the plus or distribution, we'll get nonsensical outputs. Okay. So we need to make sure that this mean function is, has like a reasonable scale. So if counts are positive, or negative, or positive impacts, we need to set the beam to something that's positive. And this is exactly the same scenario that we had before, right, we needed to make sure that probabilities are between zero and one. So we had to use a sigmoid to squash the outputs to between zero and one. Now we have count observations. So we need some nonlinear function to take to make sure that the outputs are positive and not negative. So can you think of a function that you could apply to any input such that the output will always be positives? Any what functions come to mind? Taking the absolute value would be would, would be a possibility. And it would, I would highly recommend not to do it in this case, because it would result in some really weird properties of the model. And particular, it would result in the property that the relationship between Zed and the mean, is not monotonic. So you would get this, the absolute value has this function. So you could say, so then if you change your if you change that, then increasing that can increase your prediction and decreasing that also increase their prediction. So it gives if it gives, so this non monotonicity would result in a very weird model. Okay. But that also tells us we want to have a function that map's any number to a positive number. That's a monotonic function. Any any take us yes, that that's, that's also possibility. The downside of a renal, so the renal function is just zero for negative inputs and the identity function positive inputs, what will be the downside? The downside would be that the low can be exactly zero. So you could be getting to cases where you predict an arrival rate, that's exactly zero. So the probability of So then your prediction would be the probability of observing any number of emails, let's say zero, unless, so the probability of observing any email is exactly zero. So if you then if you then observe an event, and the log probability, then you infinitely surprised you observe an event where your model said this is not this, this is impossible. And as I was mentioning earlier, it's always good to have models that leave at least some probability for even rare cases. Okay, because you can never you can never be absolutely sure. So you want a function that takes any number to a positive number. And that's monotonic. Yes, soft plus is one possibility. I will not, there isn't the simplest one is just the exponential. Okay. There are some situations where soft plus might be what you want to do. But exponential, this is the simplest thing to someone online said a leaky Renu Yes, you could be doing a leaky riilu. But you have to make sure that your leak part is such that it's always positive, okay. Otherwise it would not. Otherwise, you would run into the same problems again. So the suggestion, and in fact, what people will typically use is they would set the mean to be the exponential of this of this function. And that makes sure that the mean is always positive. And then if we did this Poisson regression, we will get the observation model of t given X given by this ugly formula, which is just this exponential of set of x, this instead of x the exponential of set of x inside the exponential of the puzzle, okay, so this is something that looks very strange because you would have an exponential of an exponential, okay. But the good news is we often we typically don't work with the with the probabilities, but with the log probabilities and then when you apply the law of probabilities, then the action potential goes go away again. Okay. And because law of exponential cancels. So in fact, one of the reasons why people would use an exponential here is because if you know, in the next step, you will have to count or you will have to take a look, then the lock, which is cancelled exponential. Okay, so there's a, there's a kind of convenient reasons for using exponential here. But depending on what you're trying to model, exponential or using soft plus might be the better modeling choice. Okay, so these are modeling choices. And in fact, this model is used. And this would give you a Poisson regression model. And this is often used to neuroscience, for example, in many other domains where you try to predict counts, given some inputs, and there's two hands. The second bracket here, that should not be here, yeah. Yeah, it doesn't. I mean, obviously, if the formula, just in contrast to the previous formula, it's still I think, clear what what is meant by that that punch up here is the second. Okay, so I think I understand your question. So if you make this exponential linearity, what do you really assuming is, if we change the input by one, then that would result in change in the mean, that's very big. If we're in a high count regime, and it's very small, even a low conversion, is that really something we want? And the answer is, in some problems, that's exactly what you want. And other problems is not what you want, and will just depend on the problem that you have, and what the correct function is. And my argument for the exponential here that I made so far, is purely one out of convenience, that this formula gets easy. But it might be a wrong model. So you might be in a regime, where for very high count numbers, you still don't want a small change in input to give to very high change in output. I can think of some examples where this behavior is actually is not too bad. So for example, and I'm making this up, I could be wrong. But intuitively, if you are, for example, trying to predict counts, let's say, maybe go back to Corona. Accounts, let's say new regime where you have 1000s, or 1000s, of infections. Yeah, you're in a very high infection regime, and then you've got some small change in input. Let's say, the number of contacts go up by a small amount, then you would think that Well, if you in this high regime, than any change in reducing contacts, also has a big effect on how many and on the mean, right? Where I mean, where if you're in a regime where you've got like a one or two or three counts, then changing something in your contact rate is not going to change the average number of, of new infections by 20. Right? Because the change from zero to 20 is a much, much bigger change than the change from 1000 to 1020. So whenever you're whenever you're maybe to rephrase this, whenever you effects a multiplicative, then you exactly want this exponential behavior, that the same change and a big regime and a big count regime is, is proportional, rather than additive, because that's what the expansion does, right? It changes these additive terms in the input to multiplicative terms. And especially for account this is often not this is often in good behavior. It's not guaranteed to be what you want, but like if you had to start somewhere, you would probably start with exponential and see whether that gives you sort of good model. Alright. So this what I define on this slide on the last two slides is a you have some knowledge about the kinds of things you want to observe the accounts and then I wrote down a recipe for how you can build a regression model that can be used to create counts, okay. And what I want to show on the next slide is last thing you want to do. So this is really a general recipe for Class A family known as generalized linear models. And you start off, but you need some model for your observations. And from the exponential family, I will not go into details on what the exponential family is, I think this is, I mean, this is you can you can look this up, or this is another course, but there's many distributions that, you know, that I'm exponential family, or can be parameterized, such that there's an exponential family. In particular, the Gaussian that we've already talked about the exponential distribution is surprisingly, in the exponential family, gamma distribution for small distribution, Bernoulli, binomial category distribution, you know, so many distributions that you know, are in the exponential family, okay. And then you can say, you, and then you pick a nonlinear function g, which maps which connects, which you apply to the input of a linear function. So that's where the generalized linear term generalized linear expression comes from, you have your linear function of the inputs that have x, you apply your nonlinear function g to it. And that gives you the mean prediction. So that gives you the prediction for the mean observation. And then you feed that me and then use that to couple that to the mean parameter of your expenses anymore. Okay, just to show you maybe make this and that gives you a regression model. And maybe this becomes a little bit more clear when I go through the examples. So in the Gaussian distribution, this g of that will just present. So the mean, of the observation is just a linear function of input. So this, this nonlinear function here is just the identity. And the Bernoulli distribution, you have said would be the sigmoid non linearity, because the mean probability of the home team winning, let's say, is a sigmoid function of the input. And in the Pulsar case, there's normally it would be the exponential function. The mean count is an exponential of this linear input. And just to introduce some terminology, as statisticians, they would, for reasons that I don't fully understand, probably, they would typically talk about the inverse of that function and call it the link function. So they would say, for Gaussian linear model, the link function is the identity. For the vanilla distribution, the link function is this, this ugly function here, which is just the inverse of the sigmoid for pasar regression, the the, they would use a log Link function. Okay, the nonlinear function that you apply to input is exponential. So if you want to go back, it's the lock. And they would, and that would be called the link function. So the link function is not this function going forward. But it's really the inverse of that. And in, and we were discussing before that, that you can, there's many link functions you can choose from, right? So we had this discussion earlier, it's not there's not like one True Link function or one through a nonlinear function that we want to use. But depending on your model, you might use one or the other function here. In the exponential family models, in the examples, that's a typo here. And there's, you can often be Rive one function, that's called the canonical Link function. And the canonical Link function might not be the right function for your problem. But in some ways, it's one that makes that has some theoretically nice properties. And it often makes the equations easier. So this, this, this was called every exponential family model has what's called a canonical Link function. And you can think of them as a function that that makes the equations and the theory look nice. And in fact, in all the examples that I discussed, the link function that we did use was the canonical function. Okay. Again, this doesn't might not be the right function for your, the problem you're trying to solve. But it's often a good starting point, because it's it's kind of the natural starting point, if you had to identification and there's a question. Yeah. So, so in general, things get more complicated when you have to do that in the Gaussian case, you can often the Gaussian has been special in the sense that this this doesn't change things. And in general, when you when you want to, when you want to model multiple of these things in parallel, then Then things often get more complicated. So it's really, it's really, the framework is really kind of easy. In some ways, if you're, if you're really trying to predict the mean, and you don't, and there's some other information that you get forgetting. And then you have some other way of setting the variance. One thing that's often done is that the variance is just fit separately. And then you plug in that term into your model. But this is really, this is really kind of the way the framework is set up is set up on the mean parameter mean parameters. And there's two boxes for this, right? So there's a GLM toolboxes, where you just write down, what's the what's the observation function? What's the likelihood term you want to have? What's the non reality you want to and then it does the rest. Okay, so partially, part of this reason, part of the motivation for this slide is that you understand the basic terminology. But if you did have a modeling problem like that, you wouldn't, you wouldn't go through all of these equations, but you would basically put this together. And then there would be optimization packages, which, which, which take care of the rest, basically. Alright. And I'm done for today. Just to summarize, I'm just going to this logistic regression, what we're talking about today is a model to predict binary outcomes. Answering yes, no questions, the cost functions associated with the logit logistic regression, both when we want to do maximum likelihood estimation. And when we want to do maximum a pulsar estimation can be efficiently optimized, because they correspond to these well behaved convex optimization problems. One has to be really careful when interpreting the output of linear regression model. The in principle, its linear influence on the output, but we have to be careful when we try to interpret them causally, and particularly when the different inputs can be correlated. And the same holds true for logistic regression. And but it's a little bit more complicated here, because here the inputs imply a linear influence on the odds on the log odds of an output event. And generalized linear models are really a recipe for building linear ish models, which are not constrained to be Gaussian distributions, but where you can have your output model to be adapted to what the right observation model is. Thank you. Any questions? All right. Alright. Thanks, everyone. 

